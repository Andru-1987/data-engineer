{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si se llega a correr con un container\n",
    "\n",
    "# docker run -d -p 5432:5439 \\\n",
    "#     -e  POSTGRES_PASSWORD=2vVUv8nSDHdusek6Lha4CYwUSqhVIcQN \\\n",
    "#     -e  POSTGRES_DB=data_engineer \\\n",
    "#     --name my-redshift \\\n",
    "#     guildeducation/docker-amazon-redshift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Una empresa llamada DBU que vende equipos deportivos al aire libre, \\\n",
    "tiene muchas ubicaciones diferentes y ha estado registrando las ventas de diferentes ubicaciones en varios productos.\\\n",
    "Quiere saber cuáles son sus mejores productos y vendedores para mejorar su rendimiento general_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base:str = \"https://raw.githubusercontent.com/CoderContenidos/Data.Engineering/main/Semana%207/Tablas/\"\n",
    "tables:list[str]= [\n",
    "    \"countryregioncurrency.csv\",\n",
    "    \"currencyrate.csv\",\n",
    "    \"product.csv\",\n",
    "    \"productcategory.csv\",\n",
    "    \"productdescription.csv\",\n",
    "    \"productmodelproductdescriptionculture.csv\",\n",
    "    \"productreview.csv\",\n",
    "    \"productsubcategory.csv\",\n",
    "    \"salesorderdetail.csv\",\n",
    "    \"salesorderheader.csv\",\n",
    "    \"salesperson.csv\",\n",
    "    \"salesterritory.csv\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes con SQL Alchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [SQLAlchemy Documentation]( https://docs.sqlalchemy.org/en/20/intro.html#installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando las librerias necesarias para hacer la conexion a la base\n",
    "from sqlalchemy import URL\n",
    "from sqlalchemy import create_engine , text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea un objeto url para conectar con la warehouse\n",
    "url_object = URL.create(\n",
    "    \"postgresql\",\n",
    "    username=os.getenv(\"PG_USERNAME\"),\n",
    "    password=os.getenv(\"PG_PASSWORD\"),\n",
    "    host=os.getenv(\"PG_HOST\"),\n",
    "    database=os.getenv(\"PG_DATABASE\"),\n",
    "    port=os.getenv(\"PG_PORT\")\n",
    "\n",
    "\n",
    "),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crear una conexion con el warehouse\n",
    "engine = create_engine(url_object[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(postgresql://postgres:***@localhost:5432/data_engineer,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conexion fallida: (psycopg2.errors.UndefinedObject) unrecognized configuration parameter \"standard_conforming_strings\"\n",
      "\n",
      "[SQL: show standard_conforming_strings]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n"
     ]
    }
   ],
   "source": [
    "# verificamos la conexion\n",
    "try:\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Conexion creada\")\n",
    "except Exception as e:\n",
    "    print(f\"Conexion fallida: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para la carga de cada dataset\n",
    "def upload_csv(**kwargs):\n",
    "    base_path = kwargs[\"base_path\"]\n",
    "    csv_file = kwargs[\"csv\"]\n",
    "    chunksize = kwargs.get(\"chunksize\", 10_000)\n",
    "    engine = kwargs[\"engine\"]\n",
    "\n",
    "    table_name = csv_file.split(\".\")[0]\n",
    "    try:\n",
    "        for chunk in pd.read_csv(base_path + csv_file, chunksize=chunksize):\n",
    "            chunk.to_sql(table_name, engine, if_exists=\"append\", index=False)\n",
    "\n",
    "        print(f\"Tabla: {table_name} ha sido completada con éxito\")\n",
    "        return 1\n",
    "    except Exception as e:\n",
    "        print(f\"La carga de la tabla: {table_name} no se realizó con éxito\")\n",
    "        return 0\n",
    "    \n",
    "# function para crear views areas funcionales\n",
    "\n",
    "def upload_views(**kwargs):\n",
    "    engine = kwargs[\"engine\"]\n",
    "    queries = kwargs[\"queries\"]\n",
    "    \n",
    "    # Transformation\n",
    "    queries_to_view = {\n",
    "        name: f\"CREATE OR REPLACE VIEW public.{name} AS\\n{query}\"\n",
    "        for name, query in queries.items()\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with engine.begin() as connection:\n",
    "            for name, view_query in queries_to_view.items():\n",
    "                connection.execute(text(view_query))\n",
    "                print(f\"View '{name}' has been created successfully\")\n",
    "\n",
    "        print(\"Transaction committed successfully\")\n",
    "        return 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create view: {e}\")\n",
    "        # Rollback the transaction in case of error\n",
    "        engine.rollback()\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_status = [upload_csv(base_path=url_base,csv=table,chunksize=10_000,engine=engine) for table in tables]\n",
    "uploaded_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREGUNTAS A RESPONDER\n",
    "* _MEJORES PRODUCTOS -> TOP PRODUCTOS EN REVIEW | TOP PRODUCTOS MAS VENDIDOS_\n",
    "* _VENDEDORES CON PEOR VENTA -> TOP N PEORES VENDEDORES_\n",
    "* _Encontrar los cinco vendedores con mejor desempeño usando la columna salesytd (Sales, year-to-date). (Solo necesitamos conocer el businessentityid de cada vendedor, ya que esto identifica de forma única a cada uno)._\n",
    "* _Usando salesorderheader, buscar los 5 mejores vendedores que hicieron la mayor cantidad de ventas en el año más reciente (2014). (Hay una columna llamada subtotal; usarla). Las ventas que no tienen un vendedor asociado deben excluirse de los cálculos y producción final. Se deben incluir todos los pedidos que se realizaron dentro del año calendario 2014.\n",
    "Pista: Pueden usar la sintaxis '1970-01-01' para generar un punto de comparación en el tiempo._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_worst_sellerstr = \"\"\"\n",
    "\n",
    "\tSELECT \n",
    "\t\tsalespersonid \n",
    "\t,\tROUND(CAST(SUM(totaldue) AS NUMERIC),2) AS TOTAL_AMOUNT_SELLED\n",
    "\t,\tCOUNT(1) AS AMOUNT_OF_SALES\n",
    "\tFROM public.salesorderheader  \n",
    "\tGROUP BY salespersonid \n",
    "\tORDER BY \n",
    "\t\tTOTAL_AMOUNT_SELLED\n",
    "\tLIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "sql_top_10_best_sells:str = \"\"\"\n",
    "WITH TOP_BEST_SELLS AS\n",
    "(\tSELECT \n",
    "\t\tS.productid\n",
    "\t,\tCOUNT(1) AS PRODUCT_TOTAL\n",
    "\tFROM public.salesorderdetail  S\n",
    "\tGROUP BY \n",
    "\t\tS.productid\n",
    "),\n",
    "AGG_TABLE as (\n",
    "SELECT \n",
    "\tproductid\n",
    ",\tP.productmodelid\n",
    ",\tP.name\n",
    ",\tPRODUCT_TOTAL\n",
    "FROM TOP_BEST_SELLS\n",
    "LEFT JOIN \n",
    "\tpublic.product AS P\n",
    "\tUSING(productid)\n",
    "ORDER BY PRODUCT_TOTAL DESC\n",
    "LIMIT 10\n",
    ")\n",
    "SELECT \n",
    "\tAG.name\n",
    ",\tPD.description\n",
    ",\tAG.PRODUCT_TOTAL\n",
    "FROM productdescription PD\n",
    "INNER JOIN productmodelproductdescriptionculture AS PC USING(productdescriptionid)\n",
    "\n",
    "INNER JOIN AGG_TABLE  AS AG USING(productmodelid)\n",
    "WHERE PC.cultureid = 'en' ;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sql_best_reviews:str = \"\"\"\n",
    "WITH producto_rating AS (\n",
    "         SELECT pv.productid,\n",
    "            p.productmodelid,\n",
    "            p.name,\n",
    "            avg(pv.rating) AS avg_rating,\n",
    "            count(1) AS total_reviews\n",
    "           FROM productreview pv\n",
    "             LEFT JOIN product p USING (productid)\n",
    "          GROUP BY pv.productid, p.name, p.productmodelid\n",
    "          ORDER BY (avg(pv.rating)) DESC\n",
    "        )\n",
    " SELECT pr.name,\n",
    "    pd.description,\n",
    "    pr.avg_rating,\n",
    "    pr.total_reviews\n",
    "   FROM productdescription pd\n",
    "     JOIN productmodelproductdescriptionculture pc USING (productdescriptionid)\n",
    "     JOIN producto_rating pr USING (productmodelid)\n",
    "  WHERE pc.cultureid = 'en'::text;\"\"\"\n",
    "\n",
    "sql_best_sales_person:str = \"\"\"\n",
    "SELECT \n",
    "   \tbusinessentityid\n",
    ",\tsalesytd\n",
    "FROM salesperson\n",
    "ORDER BY salesytd DESC\n",
    "LIMIT 5 \n",
    "\"\"\"\n",
    "sql_best_sales_person_2014:str = \"\"\"\n",
    "SELECT \n",
    "    salespersonid,\n",
    "    ROUND(SUM(subtotal)::NUMERIC, 2) AS total_sales\n",
    "FROM \n",
    "    salesorderheader\n",
    "WHERE \n",
    "    orderdate >= '2014-01-01'\n",
    "    AND salespersonid IS NOT NULL\n",
    "GROUP BY \n",
    "    salespersonid\n",
    "ORDER BY \n",
    "    total_sales DESC\n",
    "LIMIT 5;\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "queries_to_view = {    \n",
    "\t\"best_sales_person_2014_view\":sql_best_sales_person_2014,\n",
    "    \"best_sales_person_view\":sql_best_sales_person,\n",
    "    \"best_reviews_view\":sql_best_reviews,\n",
    "    \"best_sells_view\":sql_top_10_best_sells,\n",
    "    \"worst_sellers_view\" : sql_worst_sellerstr\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar carga de vistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_views(engine=engine,queries=queries_to_view)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes con Psycopg - Linux(Psycopg-binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Psycopg Documentation](https://www.psycopg.org/psycopg3/docs/basic/install.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera un objeto connector\n",
    "conn = pg.connect(\n",
    "    user=os.getenv(\"PG_USERNAME\"),\n",
    "    password=os.getenv(\"PG_PASSWORD\"),\n",
    "    host=os.getenv(\"PG_HOST\"),\n",
    "    database=os.getenv(\"PG_DATABASE\"),\n",
    "    port=os.getenv(\"PG_PORT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_creator(**kwargs):\n",
    "    connection = kwargs[\"connection\"]\n",
    "    queries = kwargs[\"queries\"]\n",
    "\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            queries_to_view = {\n",
    "                name: f\"CREATE OR REPLACE VIEW public.{name} AS\\n{query}\"\n",
    "                for name, query in queries.items()\n",
    "            }\n",
    "\n",
    "            for name, view_query in queries_to_view.items():\n",
    "                cursor.execute(view_query)\n",
    "                print(f\"View '{name}' ha sido creada\")\n",
    "\n",
    "        # Commit the transaction outside of the cursor context manager\n",
    "        connection.commit()\n",
    "        print(\"Transaction committed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error '{e}' occurred\")\n",
    "        connection.rollback() \n",
    "\n",
    "    finally:\n",
    "        connection.close()\n",
    "        print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_creator(connection=conn,queries=queries_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## psycopg2 vs SQLAlchemy\n",
    "\n",
    "| Feature         | psycopg2                                    | SQLAlchemy                                          |\n",
    "|-----------------|---------------------------------------------|-----------------------------------------------------|\n",
    "| Type            | Database adapter                            | ORM library and SQL toolkit                        |\n",
    "| Purpose         | Interact with PostgreSQL databases         | Interact with multiple database engines             |\n",
    "| Functionality   | Low-level interface for executing SQL commands, managing connections, handling transactions | ORM for mapping Python objects to database tables, SQL toolkit for query building |\n",
    "| Level of Abstraction | Low-level, requires writing SQL queries directly | High-level, provides abstraction over SQL queries, supports ORM |\n",
    "| Performance     | Known for efficiency and performance      | Offers flexibility and abstraction, may have slightly more overhead |\n",
    "| Suitability     | Developers comfortable with SQL, need direct control over PostgreSQL interactions | Developers preferring higher-level abstraction, multiple database support |\n",
    "| Learning Curve  | Easier for SQL-savvy developers            | Steeper due to ORM and higher-level abstraction    |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
